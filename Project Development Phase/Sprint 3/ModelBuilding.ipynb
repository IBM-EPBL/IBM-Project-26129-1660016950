{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Intelligent Vehicle Damage Assessment & Cost Estimator for Insurance Companies"
      ],
      "metadata": {
        "id": "KBM9L2Ykyghv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Team ID: PNT2022TMID52972**"
      ],
      "metadata": {
        "id": "NAMR3yg-x7-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Team Members: Shafiya, Nethra, Vikhas and Sam\n"
      ],
      "metadata": {
        "id": "RPXLhIUXkihd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Pre Processing"
      ],
      "metadata": {
        "id": "1DfOg_1OyknN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SLQgojHObffX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mb5zjc76bpyW"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./ 255,shear_range=0.1,zoom_range=0.1,horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.1255)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZwDR1VwMsh9",
        "outputId": "1997641a-d2f8-42f4-a06a-c5dabb01923f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KWWjjtKBb_PX"
      },
      "outputs": [],
      "source": [
        "#Body Images Path\n",
        "trainpathB = \"/content/drive/MyDrive/IBM Dataset/body/training\"\n",
        "testpathB = \"/content/drive/MyDrive/IBM Dataset/body/validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qBfC-W3_eiTC"
      },
      "outputs": [],
      "source": [
        "#Level Images Path\n",
        "trainpathL = \"/content/drive/MyDrive/IBM Dataset/level/training\";\n",
        "testpathL = \"/content/drive/MyDrive/IBM Dataset/level/validation\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the same Imagegenerator for both body and severity level\n",
        "trainB = train_datagen.flow_from_directory(trainpathB,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "testB = test_datagen.flow_from_directory(trainpathB,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 10,\n",
        "                                            class_mode ='categorical' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abm1unIYl2ko",
        "outputId": "ba70c252-dc4c-4018-afa4-d4eefcae51af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 979 images belonging to 3 classes.\n",
            "Found 979 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainL = train_datagen.flow_from_directory(trainpathL,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "testL = test_datagen.flow_from_directory(trainpathL,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 10,\n",
        "                                            class_mode ='categorical' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VuZgGMTlsR0",
        "outputId": "c04a0c8d-7c62-4d06-f0ef-3bb5af591298"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 979 images belonging to 3 classes.\n",
            "Found 979 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "Z7t7P2NZouI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "7CTXfX87ox6U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input"
      ],
      "metadata": {
        "id": "uP5F50K0otDv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding preprocessed layers to the Transfer Model\n",
        "vgg=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(224,224,3)))\n",
        "vgg1=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(224,224,3)))"
      ],
      "metadata": {
        "id": "bqVI79VKo0Av"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tq0g5Q6TjCQm"
      },
      "outputs": [],
      "source": [
        "for layer in vgg.layers:\n",
        "    layer.trainable=False\n",
        "x=Flatten()(vgg.output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg1.layers:\n",
        "    layer.trainable=False\n",
        "y=Flatten()(vgg1.output)"
      ],
      "metadata": {
        "id": "L0wy-liFpner"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YSdIvzyXjU5X"
      },
      "outputs": [],
      "source": [
        "pred = Dense(3,activation='softmax')(x)\n",
        "pred1 = Dense(3,activation='softmax')(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WEgjqXhEjxCp"
      },
      "outputs": [],
      "source": [
        "model =  Model(inputs=vgg.input,outputs=pred)\n",
        "model1 = Model(inputs=vgg1.input,outputs=pred1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NHMwWlpgjzix"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model for Body regions of the Car"
      ],
      "metadata": {
        "id": "8Z67t73KyLco"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsrBpvFMj2rK",
        "outputId": "01f046a5-488f-40b0-b450-a69263d6c868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "97/97 [==============================] - 321s 3s/step - loss: 1.1619 - acc: 0.5387 - val_loss: 21.5601 - val_acc: 0.6882\n",
            "Epoch 2/25\n",
            "97/97 [==============================] - 16s 162ms/step - loss: 0.6938 - acc: 0.7451 - val_loss: 19.1161 - val_acc: 0.7353\n",
            "Epoch 3/25\n",
            "97/97 [==============================] - 15s 150ms/step - loss: 0.5582 - acc: 0.7802 - val_loss: 22.2818 - val_acc: 0.7471\n",
            "Epoch 4/25\n",
            "97/97 [==============================] - 14s 148ms/step - loss: 0.3943 - acc: 0.8504 - val_loss: 18.3699 - val_acc: 0.7941\n",
            "Epoch 5/25\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 0.2416 - acc: 0.9154 - val_loss: 13.6339 - val_acc: 0.8294\n",
            "Epoch 6/25\n",
            "97/97 [==============================] - 15s 156ms/step - loss: 0.2263 - acc: 0.9257 - val_loss: 19.8580 - val_acc: 0.8118\n",
            "Epoch 7/25\n",
            "97/97 [==============================] - 15s 149ms/step - loss: 0.1523 - acc: 0.9463 - val_loss: 14.0755 - val_acc: 0.7882\n",
            "Epoch 8/25\n",
            "97/97 [==============================] - 15s 151ms/step - loss: 0.1899 - acc: 0.9319 - val_loss: 23.8977 - val_acc: 0.7647\n",
            "Epoch 9/25\n",
            "97/97 [==============================] - 16s 167ms/step - loss: 0.1506 - acc: 0.9515 - val_loss: 15.6135 - val_acc: 0.8353\n",
            "Epoch 10/25\n",
            "97/97 [==============================] - 16s 161ms/step - loss: 0.1756 - acc: 0.9391 - val_loss: 17.1979 - val_acc: 0.7824\n",
            "Epoch 11/25\n",
            "97/97 [==============================] - 15s 149ms/step - loss: 0.1159 - acc: 0.9577 - val_loss: 18.8640 - val_acc: 0.7588\n",
            "Epoch 12/25\n",
            "97/97 [==============================] - 16s 160ms/step - loss: 0.0924 - acc: 0.9732 - val_loss: 17.7827 - val_acc: 0.7941\n",
            "Epoch 13/25\n",
            "97/97 [==============================] - 15s 149ms/step - loss: 0.0796 - acc: 0.9752 - val_loss: 18.5161 - val_acc: 0.7941\n",
            "Epoch 14/25\n",
            "97/97 [==============================] - 15s 149ms/step - loss: 0.1916 - acc: 0.9257 - val_loss: 21.8456 - val_acc: 0.8176\n",
            "Epoch 15/25\n",
            "97/97 [==============================] - 15s 150ms/step - loss: 0.1209 - acc: 0.9598 - val_loss: 32.9898 - val_acc: 0.7059\n",
            "Epoch 16/25\n",
            "97/97 [==============================] - 15s 150ms/step - loss: 0.0858 - acc: 0.9732 - val_loss: 23.6963 - val_acc: 0.8059\n",
            "Epoch 17/25\n",
            "97/97 [==============================] - 14s 148ms/step - loss: 0.0401 - acc: 0.9917 - val_loss: 22.4229 - val_acc: 0.8235\n",
            "Epoch 18/25\n",
            "97/97 [==============================] - 15s 149ms/step - loss: 0.1148 - acc: 0.9639 - val_loss: 27.8105 - val_acc: 0.8176\n",
            "Epoch 19/25\n",
            "97/97 [==============================] - 14s 148ms/step - loss: 0.0569 - acc: 0.9825 - val_loss: 34.2578 - val_acc: 0.7412\n",
            "Epoch 20/25\n",
            "97/97 [==============================] - 15s 149ms/step - loss: 0.0752 - acc: 0.9856 - val_loss: 20.9876 - val_acc: 0.8647\n",
            "Epoch 21/25\n",
            "97/97 [==============================] - 15s 151ms/step - loss: 0.0658 - acc: 0.9886 - val_loss: 29.4785 - val_acc: 0.7824\n",
            "Epoch 22/25\n",
            "97/97 [==============================] - 16s 159ms/step - loss: 0.0766 - acc: 0.9804 - val_loss: 25.9757 - val_acc: 0.7941\n",
            "Epoch 23/25\n",
            "97/97 [==============================] - 15s 149ms/step - loss: 0.0634 - acc: 0.9835 - val_loss: 32.9211 - val_acc: 0.7706\n",
            "Epoch 24/25\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 0.0425 - acc: 0.9876 - val_loss: 25.6515 - val_acc: 0.8176\n",
            "Epoch 25/25\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 0.0778 - acc: 0.9742 - val_loss: 26.5239 - val_acc: 0.8176\n"
          ]
        }
      ],
      "source": [
        "r=model.fit_generator(trainB,\n",
        "                      validation_data=testB,\n",
        "                      epochs=25,\n",
        "                      steps_per_epoch=979//10,\n",
        "                      validation_steps=171//10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('BodyModel.h5')"
      ],
      "metadata": {
        "id": "Yv3ttVbZ0VQI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model for Damage severity level"
      ],
      "metadata": {
        "id": "4wzvS9sTySyr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2095aa-4316-4959-c5b2-d0baa964b0b6",
        "id": "i0NsrNrfwgXD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97/97 [==============================] - 15s 149ms/step - loss: 1.1220 - acc: 0.5697 - val_loss: 20.5935 - val_acc: 0.6471\n",
            "Epoch 2/25\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 0.7317 - acc: 0.7214 - val_loss: 16.6535 - val_acc: 0.7000\n",
            "Epoch 3/25\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 0.4896 - acc: 0.8101 - val_loss: 21.9476 - val_acc: 0.6824\n",
            "Epoch 4/25\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 0.3987 - acc: 0.8483 - val_loss: 26.3160 - val_acc: 0.7000\n",
            "Epoch 5/25\n",
            "97/97 [==============================] - 14s 147ms/step - loss: 0.3976 - acc: 0.8514 - val_loss: 19.4099 - val_acc: 0.7882\n",
            "Epoch 6/25\n",
            "97/97 [==============================] - 15s 153ms/step - loss: 0.2790 - acc: 0.9071 - val_loss: 25.6266 - val_acc: 0.7471\n",
            "Epoch 7/25\n",
            "97/97 [==============================] - 15s 149ms/step - loss: 0.2371 - acc: 0.9123 - val_loss: 21.1236 - val_acc: 0.7882\n",
            "Epoch 8/25\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 0.1706 - acc: 0.9422 - val_loss: 22.4431 - val_acc: 0.7765\n",
            "Epoch 9/25\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 0.1352 - acc: 0.9567 - val_loss: 36.1602 - val_acc: 0.7000\n",
            "Epoch 10/25\n",
            "97/97 [==============================] - 16s 165ms/step - loss: 0.0849 - acc: 0.9783 - val_loss: 20.9657 - val_acc: 0.7765\n",
            "Epoch 11/25\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 0.0721 - acc: 0.9804 - val_loss: 24.5829 - val_acc: 0.7118\n",
            "Epoch 12/25\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 0.0661 - acc: 0.9866 - val_loss: 25.7153 - val_acc: 0.8000\n",
            "Epoch 13/25\n",
            "97/97 [==============================] - 15s 157ms/step - loss: 0.0548 - acc: 0.9876 - val_loss: 34.9697 - val_acc: 0.7529\n",
            "Epoch 14/25\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 0.0509 - acc: 0.9886 - val_loss: 25.5591 - val_acc: 0.7471\n",
            "Epoch 15/25\n",
            "97/97 [==============================] - 14s 144ms/step - loss: 0.0593 - acc: 0.9866 - val_loss: 24.7924 - val_acc: 0.7941\n",
            "Epoch 16/25\n",
            "97/97 [==============================] - 15s 155ms/step - loss: 0.0534 - acc: 0.9876 - val_loss: 24.8444 - val_acc: 0.7882\n",
            "Epoch 17/25\n",
            "97/97 [==============================] - 14s 145ms/step - loss: 0.0762 - acc: 0.9721 - val_loss: 22.0487 - val_acc: 0.8059\n",
            "Epoch 18/25\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 0.0443 - acc: 0.9948 - val_loss: 25.9376 - val_acc: 0.8059\n",
            "Epoch 19/25\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 0.0299 - acc: 0.9959 - val_loss: 31.0126 - val_acc: 0.7824\n",
            "Epoch 20/25\n",
            "97/97 [==============================] - 15s 151ms/step - loss: 0.0513 - acc: 0.9897 - val_loss: 19.4266 - val_acc: 0.8412\n",
            "Epoch 21/25\n",
            "97/97 [==============================] - 14s 144ms/step - loss: 0.0488 - acc: 0.9876 - val_loss: 25.1696 - val_acc: 0.7765\n",
            "Epoch 22/25\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 0.0238 - acc: 0.9969 - val_loss: 21.5541 - val_acc: 0.8235\n",
            "Epoch 23/25\n",
            "97/97 [==============================] - 16s 170ms/step - loss: 0.0245 - acc: 0.9969 - val_loss: 15.4230 - val_acc: 0.8059\n",
            "Epoch 24/25\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 0.0204 - acc: 0.9979 - val_loss: 36.8876 - val_acc: 0.6941\n",
            "Epoch 25/25\n",
            "97/97 [==============================] - 14s 146ms/step - loss: 0.0182 - acc: 0.9979 - val_loss: 25.5283 - val_acc: 0.8059\n"
          ]
        }
      ],
      "source": [
        "r1= model1.fit_generator(trainL,\n",
        "                        validation_data=testL,\n",
        "                        epochs=25,\n",
        "                        steps_per_epoch=979//10,\n",
        "                        validation_steps=171//10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('/content/drive/MyDrive/models/level.h5')"
      ],
      "metadata": {
        "id": "W0WKKQ_IwgXE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FN3PHqaimp52"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "body_model=load_model('/content/BodyModel.h5')"
      ],
      "metadata": {
        "id": "JrYDs6cM-03Z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "rpnGI5GN-4Vv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "    img=cv2.resize(frame,(224,224))\n",
        "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    if(np.max(img)>1):\n",
        "        img=img/255.0\n",
        "    img=np.array([img])\n",
        "    prediction =body_model.predict(img)\n",
        "    #print(prediction)\n",
        "    label=[\"front\",\"rear\",\"side\"]\n",
        "    preds=label[np.argmax(prediction)]\n",
        "    return preds"
      ],
      "metadata": {
        "id": "SbPPDPNH-zW0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rLnqPmZPmtAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7621879-37d4-4df9-dd38-6a5abbdabeaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 810ms/step\n",
            "rear\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "data=\"/content/drive/MyDrive/IBM Dataset/body/validation/01-rear/0002.JPEG\"\n",
        "image=cv2.imread(data)\n",
        "print(detect(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "w77deZQ3nPBo"
      },
      "outputs": [],
      "source": [
        "level_model = load_model('/content/drive/MyDrive/models/level.h5')\n",
        "\n",
        "\n",
        "def detect1(frame):\n",
        "    img = cv2.resize(frame, (224, 224))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    if(np.max(img) > 1):\n",
        "        img = img/255.0\n",
        "    img = np.array([img])\n",
        "    prediction = level_model.predict(img)\n",
        "    print(prediction)\n",
        "    label = [\"minor\", \"moderate\", \"severe\"]\n",
        "    preds = label[np.argmax(prediction)]\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "fTQ2XSB3nUPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8caa217c-4117-4d7d-bc2c-c66dbca33284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "[[1.8254417e-05 2.8804177e-04 9.9969375e-01]]\n",
            "severe\n"
          ]
        }
      ],
      "source": [
        "data = \"/content/drive/MyDrive/IBM Dataset/level/validation/03-severe/0004.JPEG\"\n",
        "image = cv2.imread(data)\n",
        "print(detect1(image))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}